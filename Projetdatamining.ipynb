{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN86fMGeIx28JX/yngwWv9u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymanezzouhairi/datamining/blob/main/Projetdatamining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kw7DHFL0hzw",
        "outputId": "fb8a8dfa-2f46-48f1-fa4b-c64d2eb7ecb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aperçu des données :\n",
            "        ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n",
            "0  458989  Female          Yes   36       Yes    Engineer              0.0   \n",
            "1  458994    Male          Yes   37       Yes  Healthcare              8.0   \n",
            "2  458996  Female          Yes   69        No         NaN              0.0   \n",
            "3  459000    Male          Yes   59        No   Executive             11.0   \n",
            "4  459001  Female           No   19        No   Marketing              NaN   \n",
            "\n",
            "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
            "0            Low          1.0  Cat_6            B  \n",
            "1        Average          4.0  Cat_6            A  \n",
            "2            Low          1.0  Cat_6            A  \n",
            "3           High          2.0  Cat_6            B  \n",
            "4            Low          4.0  Cat_6            A  \n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.61      0.42       177\n",
            "           1       0.00      0.00      0.00        97\n",
            "           2       0.00      0.00      0.00       116\n",
            "           3       0.33      0.47      0.39       136\n",
            "\n",
            "    accuracy                           0.33       526\n",
            "   macro avg       0.16      0.27      0.20       526\n",
            "weighted avg       0.19      0.33      0.24       526\n",
            "\n",
            "Naive Bayes Accuracy: 0.3403041825095057\n",
            "Complement Naive Bayes Accuracy: 0.3231939163498099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Charger les données\n",
        "data = pd.read_csv('Test.csv')  # Remplacez par votre chemin\n",
        "print(\"Aperçu des données :\\n\", data.head())\n",
        "\n",
        "# Identifier les colonnes numériques et catégoriques\n",
        "numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# 1. Gestion des valeurs manquantes\n",
        "# Remplacer les valeurs manquantes dans les colonnes numériques par la moyenne\n",
        "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n",
        "\n",
        "# Remplacer les valeurs manquantes dans les colonnes catégoriques par le mode\n",
        "for col in categorical_columns:\n",
        "    data[col] = data[col].fillna(data[col].mode()[0])\n",
        "\n",
        "# 2. Encodage des variables catégoriques\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    data[col] = label_encoders[col].fit_transform(data[col].astype(str))\n",
        "\n",
        "# Séparation des caractéristiques et de la cible\n",
        "X = data.drop(columns=['ID', 'Segmentation'])\n",
        "y = LabelEncoder().fit_transform(data['Segmentation'])\n",
        "\n",
        "# 3. Normalisation des données avec Min-Max Scaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 4. Sélection des caractéristiques avec Chi-square test\n",
        "chi2_selector = SelectKBest(chi2, k=8)  # Sélectionne les 8 meilleures caractéristiques\n",
        "X_selected = chi2_selector.fit_transform(X_scaled, y)\n",
        "\n",
        "# 5. Division des données pour la classification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modèle SVM\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Modèle Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Modèle Complement Naive Bayes\n",
        "cnb_model = ComplementNB()\n",
        "cnb_model.fit(X_train, y_train)\n",
        "y_pred_cnb = cnb_model.predict(X_test)\n",
        "\n",
        "# Évaluation des modèles\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Complement Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_cnb))\n"
      ]
    }
  ]
}